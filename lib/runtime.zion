module runtime

# the zion runtime and garbage collector

/*  The head of the singly-linked list of llvm_stack_entry_t's.  Functions push
 *  and pop onto this in their prologue and epilogue.
 * 
 *  Since there is only a global list, this technique is not threadsafe. */
link var llvm_gc_root_chain *llvm_stack_entry_t

var TYPE_ID_VECTOR __int32__ = __int32__(-2r)
var __debug_zion_runtime __int__ = 0r
var _zion_rt __str__ = "zion-rt: "r


#define GET_CHILD_REF(var, index) \
#           (*(struct var_t **)(((char *)var) + \
#                               ((struct type_info_offsets_t *)var.type_info).ref_offsets[index]))

type var_t struct
	var type_info *type_info_t
	# and a ref-count of its own
	var mark __int__
	var next *var_t
	var prev *var_t
	var allocation __int__
	#
	# THE ACTUAL DATA IS APPENDED HERE
	#

type type_info_t struct
	var type_id   __int32__
	var type_kind __int32__
	var size      __int__
	var name      __str__

type type_info_offsets_t struct
	var type_info_head type_info_t
	var finalize_fn    def (v *var_t) void
	var refs_count     __int16__
	var ref_offsets    *__int16__

type type_info_mark_fn_t struct
	var type_info_head type_info_t

	# the destructor for this type, if one exists. NB: if you change the index
	# of this dimension, update DTOR_INDEX
	var finalize_fn def (v *var_t) void

	# the mark function for this type, if one exists. NB: if you change the index
	# of this dimension, update MARK_FN_INDEX
	var mark_fn def (v *var_t) void

type tag_t struct
	var type_info *type_info_t


var _bytes_allocated __int__ = 0r
var _all_bytes_allocated __int__ = 0r

def mem_alloc(cb __int__) *void
	_bytes_allocated += cb
	_all_bytes_allocated += cb
	# dbg_zrt(printf("memory allocation is at %ld %ld\n", _bytes_allocated, _all_bytes_allocated))

	return posix.calloc(cb, 1r)

def mem_free(p *void, cb __int__) void
	_bytes_allocated -= cb
	posix.free(p)
	# dbg_zrt(printf("memory allocation is at %ld %ld\n", _bytes_allocated, _all_bytes_allocated))

def get_total_allocated() __int__
	return _bytes_allocated

/*
#define MEM_PANIC(msg, str, error_code) \
	do { \
		write(2, _zion_rt, strlen(_zion_rt)) \
		write(2, msg, strlen(msg)) \
		write(2, str, strlen(str)) \
		write(2, "\n", 1) \
		exit(error_code) \
	} while (0)
*/


var head_var *var_t = create_var(nil)

def check_node_existence(node *var_t, should_exist __bool__) void
	p := &head_var
	assert(p.prev == nil)

	if should_exist
		assert(p.next != nil)
		assert(node != nil)
		assert(node.prev != 3735928559r as *var_t)
		assert(node.next != 3735928559r as *var_t)
		assert(node.prev != nil)

	while p != nil
		if p == node
			if not should_exist
				# dbg_zrt(printf("node 0x%08lx of type %s already exists!\n", (intptr_t)node, node.type_info.name))
				assert(should_exist)
			else
				# found it, and that's expected.
				return
		p = p.next

	if should_exist
		# dbg_zrt(printf("node 0x%08lx #%lld of type %s does not exist in memory tracking list!\n", (intptr_t)node, (long long)node.allocation, node.type_info.name))
		assert(not should_exist)


def add_node(node *var_t) void
	check_node_existence(node, 0)

	if node.prev != nil or node.next != nil
		# dbg_zrt(printf("node 0x%08lx #%lld of type %s already has prev and next ptrs?!\n", (intptr_t)node, (long long)node.allocation, node.type_info.name))
		posix.exit(-1r)

	/* assert(not head_var.next or head_var.next.prev == &head_var) */

	node.prev = &head_var
	node.next = head_var.next
	if node.next != nil
		node.next.prev = node

	head_var.next = node

	assert(head_var.prev == nil)
	assert(head_var.next.prev == &head_var)
	assert(node.prev.next == node)
	assert(not node.next or node.next.prev == node)

	check_node_existence(node, 1)

def remove_node(node *var_t) void
	/* dbg_zrt(printf("removing node 0x%08llx %s\n",
				(long long)node, node.type_info.name)) */
	assert(node.mark == 0r)

	check_node_existence(node, 1 /* should_exist */)

	assert(node.prev.next == node)
	assert(not node.next or node.next.prev == node)

	node.prev.next = node.next
	if node.next != nil
		node.next.prev = node.prev
	node.next = 3735928559r as *var_t
	node.prev = 3735928559r as *var_t

	check_node_existence(node, 0r)

def isnil(p *var_t) __bool__
	return p == nil

def get_var_type_id(v *var_t) __int32__
	if v != nil
		return v.type_info.type_id
	else
		# MEM_PANIC("attempt to get_var_type_id of a null value ", "", 116)
		return 0r

var _allocation __int__ = 1r

def create_var(type_info *type_info_t) *var_t
	/* allocate the variable tracking object */
	var obj *var_t = mem_alloc(type_info.size) as *var_t
	obj.type_info = type_info
	obj.ref_count = 1

	/* track this allocation */
	obj.allocation = _allocation
	_allocation += 1r

	add_node(obj)

	/* dbg_zrt(printf("creating %s #%lld 0x%08lx\n", type_info.name, obj.allocation, (intptr_t)obj)) */

	return obj

/*  The map for a single function's stack frame.  One of these is
 *  compiled as constant data into the executable for each function.
 * 
 *  Storage of metadata values is elided if the %metadata parameter to
 *  @llvm.gcroot is null. */
type stack_frame_map_t struct
	var num_roots __int32__  # Number of roots in stack frame.
	var num_meta  __int32__  # Number of metadata entries.  May be < num_roots.
	var meta      **void     # Metadata for each root.

/*  A link in the dynamic shadow stack.  One of these is embedded in
 *  the stack frame of each function on the call stack. */
type llvm_stack_entry_t struct
	var next *llvm_stack_entry_t  # Link to next stack entry (the caller's).
	var map  *stack_frame_map_t   # Pointer to constant stack_frame_map_t.
	var stack_roots **var_t       # Stack roots (in-place array).

/* Calls heap_visit(root, meta) for each GC root on the stack.
 *        root and meta are exactly the values passed to
 *        @llvm.gcroot.
 *
 * heap_visit could be a function to recursively mark live objects.  Or it
 * might copy them to another heap or generation.
 *
 * @param heap_visit A function to invoke for every GC root on the stack. */
def visit_heap_roots(heap_visit def (obj *void) void)
	R := llvm_gc_root_chain
	while R != nil
		assert(R.map.num_meta == 0r)

		# For roots [num_meta, num_roots), the metadata pointer is null.
		i := 0r
		e := R.map.num_roots
		while i != e
			/* we have a heap variable */
			heap_visit(R.stack_roots[i])
			i += 1r

		R = R.next


def visit_allocations(visit def (obj *var_t) void)
	node := head_var.next
	while node != nil
		# cache the next node in case our current node gets deleted as part of the fn
		next := node.next

		# visit the node
		visit(node)

		# move along
		node = next


def mark_allocation(obj *var_t)
	if obj == nil
		return

	# dbg_zrt(printf("heap variable is referenced on the stack at 0x%08llx and is a '%s'\n", (long long)obj, obj.type_info.name))
	if obj.mark != 0r
		return

	# mark this node in the heap so that we break any potential cycles
	obj.mark = 1r

	# dbg_zrt(printf("marking heap variable at 0x%08llx '%s'\n", (long long)obj, obj.type_info.name))

	assert(obj.type_info)

	type_kind := __int__(obj.type_info.type_kind)

	if type_kind == 0r /* type_kind_tag */
		# tags don't have dependencies
		return
	elif type_kind == 1r /* type_kind_use_offsets */
		var type_info_offsets *type_info_offsets_t = obj.type_info as *type_info_offsets_t

		# we may be holding on to child nodes, let's recurse.
		var refs_count __int__ = __int__(type_info_offsets.refs_count)

		j := 0r
		while j < refs_count
			/* compute the offset to this referenced dimension */
			var child *var_t = GET_CHILD_REF(obj, j)
			mark_allocation(child)
			j += 1r
	elif type_kind == 2r /* type_kind_use_mark_fn */
		# call the type's mark function to recurse
		type_info_mark_fn := obj.type_info as *type_info_mark_fn_t
		type_info_mark_fn.mark_fn(obj)
	else
		posix.perror("found a heap variable with an invalid type_kind"r)
		posix.exit(1r)


def clear_mark_bit(obj *var_t)
	# this is highly inefficient due to cache non-locality, revisit later
	obj.mark = 0


def free_unmarked(obj *var_t)
	assert(obj != head_var)
	if obj.mark == 0r
		remove_node(obj)
		mem_free(obj, obj.type_info.size)


def gc()
	__debug_zion_runtime = posix.getenv("DBG_ZRT"r) != nil
	# HACK: because type unification does not seem to work well when linking IR
	# from C . llir . in-memory Zion, we are just using the void * type to allow
	# for a "universal" translation layer between modules.
	visit_allocations(clear_mark_bit)
	visit_heap_roots(mark_allocation)
	visit_allocations(free_unmarked)


def print_var(node *var_t)
	# printf("heap variable is still allocated at 0x%08llx and is a '%s'\n", (long long)node, node.type_info.name)
	pass


def heap_dump()
	visit_allocations(print_var)
